#!/usr/bin/env python
"""
æ·±åº¦è¯Šæ–­å¹¶è¡Œæ‰§è¡Œå¡æ­»é—®é¢˜

ä¸ run_std_quick ç›¸åŒè§„æ¨¡:
- 9 agents
- n_configs=3
- n_steps=50
- ä¸è®¾ç½® max_worlds_per_configï¼ˆè®©å®ƒç”Ÿæˆæ‰€æœ‰ç»„åˆï¼‰
- ä¸è®¾ç½® total_timeout

ç›‘æ§æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶: diagnose_logs/monitor_*.log
"""

import os
import sys
import time
import atexit
import signal
import json
import threading
from pathlib import Path
from datetime import datetime

PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))

# ä½¿ç”¨ spawn ä¿æŒä¸é»˜è®¤ ProcessPoolExecutor è¡Œä¸ºä¸€è‡´
import multiprocessing as mp
try:
    mp.set_start_method("spawn")
except RuntimeError:
    pass

os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR = PROJECT_ROOT / "diagnose_logs"
LOG_DIR.mkdir(exist_ok=True)

# ç»“æœç›®å½•ï¼ˆç¡®ä¿åœ¨æ²™ç®±å†…å†™å…¥ï¼‰
RESULTS_ROOT = PROJECT_ROOT / "results"
RESULTS_ROOT.mkdir(exist_ok=True)

# æ—¥å¿—æ–‡ä»¶
TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')
MONITOR_LOG = LOG_DIR / f"monitor_{TIMESTAMP}.log"
MAIN_LOG = LOG_DIR / f"main_{TIMESTAMP}.log"
TOURNAMENT_DIR = RESULTS_ROOT / f"clean_run_{TIMESTAMP}"
TOURNAMENT_DIR.mkdir(parents=True, exist_ok=True)
WORKER_TRACE = LOG_DIR / f"worker_trace_{TIMESTAMP}.log"
FUTURE_TRACE = LOG_DIR / f"future_trace_{TIMESTAMP}.log"
MONITOR_TRACE = LOG_DIR / f"executor_monitor_{TIMESTAMP}.log"


def log_to_file(filepath, message):
    """å†™å…¥æ—¥å¿—æ–‡ä»¶"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
    with open(filepath, 'a', encoding='utf-8') as f:
        f.write(f"[{timestamp}] {message}\n")
        f.flush()


def log_trace(event: str, **data):
    """è®°å½• worker çº§åˆ«çš„å…³é”®äº‹ä»¶"""
    payload = {"event": event, "pid": os.getpid(), "ts": time.time()}
    payload.update(data)
    with open(WORKER_TRACE, "a", encoding="utf-8") as f:
        f.write(json.dumps(payload, ensure_ascii=False) + "\n")
        f.flush()


def log_future(event: str, **data):
    """è®°å½• future çŠ¶æ€"""
    payload = {"event": event, "pid": os.getpid(), "ts": time.time()}
    payload.update(data)
    with open(FUTURE_TRACE, "a", encoding="utf-8") as f:
        f.write(json.dumps(payload, ensure_ascii=False) + "\n")
        f.flush()


_ORIGINAL_RUN_WORLDS = None
_REQUESTED_PARALLELISM = None


def traced_run_worlds(
    worlds_params,
    world_generator,
    score_calculator,
    world_progress_callback,
    dry_run,
    save_world_stats,
    override_ran_worlds,
    save_progress_every,
    attempts_path,
    max_attempts,
    verbose,
):
    """é¡¶å±‚å®šä¹‰ä»¥æ”¯æŒ spawn pickling"""
    global _ORIGINAL_RUN_WORLDS
    try:
        import negmas.tournaments.tournaments as nt  # å»¶è¿Ÿ import ä¾¿äº pickling
        run_id = nt._hash(worlds_params)
    except Exception:
        run_id = None
    names = []
    try:
        for wp in worlds_params:
            name = None
            if isinstance(wp, dict):
                wp_info = wp.get("world_params") or {}
                name = wp_info.get("name") or wp_info.get("config_id")
            names.append(name)
    except Exception:
        pass
    log_trace("worker_start", run_id=run_id, names=names)
    atexit.register(lambda: log_trace("worker_exit", run_id=run_id))
    try:
        if _ORIGINAL_RUN_WORLDS is None:
            import negmas.tournaments.tournaments as nt  # type: ignore
            _ORIGINAL_RUN_WORLDS = nt.__dict__.get("_run_worlds")
        result = _ORIGINAL_RUN_WORLDS(
            worlds_params,
            world_generator,
            score_calculator,
            world_progress_callback,
            dry_run,
            save_world_stats,
            override_ran_worlds,
            save_progress_every,
            attempts_path,
            max_attempts,
            verbose,
        )
        log_trace("worker_done", run_id=run_id)
        return result
    except Exception as e:
        log_trace("worker_error", run_id=run_id, error=str(e))
        raise


def get_child_processes_detailed():
    """è·å–æ‰€æœ‰å­è¿›ç¨‹çš„è¯¦ç»†ä¿¡æ¯"""
    import subprocess
    try:
        # è·å–å½“å‰è¿›ç¨‹çš„æ‰€æœ‰å­è¿›ç¨‹
        result = subprocess.run(
            ['ps', '-o', 'pid,ppid,state,%cpu,%mem,etime,cmd', '--ppid', str(os.getpid())],
            capture_output=True, text=True, timeout=5
        )
        return result.stdout
    except Exception as e:
        return f"Error: {e}"


def get_all_python_processes():
    """è·å–ç³»ç»Ÿä¸­æ‰€æœ‰ Python è¿›ç¨‹"""
    import subprocess
    try:
        result = subprocess.run(
            ['ps', 'aux'],
            capture_output=True, text=True, timeout=5
        )
        lines = result.stdout.split('\n')
        python_lines = [l for l in lines if 'python' in l.lower()]
        return '\n'.join(python_lines)
    except Exception as e:
        return f"Error: {e}"


def get_system_load():
    """è·å–ç³»ç»Ÿè´Ÿè½½"""
    try:
        with open('/proc/loadavg', 'r') as f:
            return f.read().strip()
    except:
        return "N/A"


class ProcessMonitor:
    """è¿›ç¨‹ç›‘æ§å™¨"""
    
    def __init__(self, log_file, interval=5):
        self.log_file = log_file
        self.interval = interval
        self.stop_event = threading.Event()
        self.thread = None
        self.start_time = time.time()
        self.last_child_count = 0
        self.stall_count = 0
        self.progress_history = []
        
    def start(self):
        """å¯åŠ¨ç›‘æ§"""
        self.thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.thread.start()
        log_to_file(self.log_file, "=" * 80)
        log_to_file(self.log_file, "ç›‘æ§å¯åŠ¨")
        log_to_file(self.log_file, f"ä¸»è¿›ç¨‹ PID: {os.getpid()}")
        log_to_file(self.log_file, "=" * 80)
        
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self.stop_event.set()
        if self.thread:
            self.thread.join(timeout=2)
        log_to_file(self.log_file, "ç›‘æ§åœæ­¢")
        
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        check_count = 0
        while not self.stop_event.is_set():
            time.sleep(self.interval)
            check_count += 1
            elapsed = time.time() - self.start_time
            
            # è·å–å­è¿›ç¨‹ä¿¡æ¯
            child_info = get_child_processes_detailed()
            child_lines = [l for l in child_info.split('\n') if l.strip() and 'PID' not in l]
            child_count = len(child_lines)
            
            # ç»Ÿè®¡çŠ¶æ€
            states = {}
            for line in child_lines:
                parts = line.split()
                if len(parts) >= 3:
                    state = parts[2]
                    states[state] = states.get(state, 0) + 1
            
            # ç³»ç»Ÿè´Ÿè½½
            load = get_system_load()
            
            # è®°å½•
            log_to_file(self.log_file, "-" * 60)
            log_to_file(self.log_file, f"æ£€æŸ¥ #{check_count} | è¿è¡Œæ—¶é—´: {elapsed:.0f}s | ç³»ç»Ÿè´Ÿè½½: {load}")
            log_to_file(self.log_file, f"å­è¿›ç¨‹æ•°: {child_count} | çŠ¶æ€åˆ†å¸ƒ: {states}")
            
            # æ£€æµ‹å¼‚å¸¸
            if child_count == 0 and elapsed > 30:
                self.stall_count += 1
                log_to_file(self.log_file, f"âš ï¸ è­¦å‘Š: æ²¡æœ‰å­è¿›ç¨‹! è¿ç»­ {self.stall_count} æ¬¡")
                
                if self.stall_count >= 3:
                    log_to_file(self.log_file, "âŒ å¯èƒ½å·²å¡æ­»! è®°å½•æ‰€æœ‰ Python è¿›ç¨‹:")
                    all_python = get_all_python_processes()
                    log_to_file(self.log_file, all_python)
            else:
                self.stall_count = 0
            
            # è®°å½•å­è¿›ç¨‹å˜åŒ–
            if child_count != self.last_child_count:
                log_to_file(self.log_file, f"å­è¿›ç¨‹æ•°å˜åŒ–: {self.last_child_count} -> {child_count}")
                self.last_child_count = child_count
            
            # æ¯åˆ†é’Ÿè®°å½•ä¸€æ¬¡è¯¦ç»†ä¿¡æ¯
            if check_count % 12 == 0:  # æ¯ 60 ç§’
                log_to_file(self.log_file, "=== è¯¦ç»†å­è¿›ç¨‹åˆ—è¡¨ ===")
                log_to_file(self.log_file, child_info)


def main():
    import matplotlib
    matplotlib.use('Agg')
    
    # ç»™å­è¿›ç¨‹ä¼ é€’ç¯å¢ƒå˜é‡ï¼Œè§¦å‘ sitecustomize.py ä¸­çš„ worker è¿½è¸ªè¡¥ä¸
    os.environ["SCML_PATCH_WORKER_TRACE"] = "1"
    os.environ["SCML_WORKER_TRACE_FILE"] = str(WORKER_TRACE)
    os.environ["PYTHONFAULTHANDLER"] = "1"
    os.environ["PYTHONPATH"] = f"{PROJECT_ROOT}{os.pathsep}" + os.environ.get("PYTHONPATH", "")

    # ç›´æ¥åœ¨çˆ¶è¿›ç¨‹ä¸­ monkeypatch negmas._run_worldsï¼ˆfork æ¨¡å¼ä¼šç»§æ‰¿ï¼Œspawn ä¹Ÿå¯ picklingï¼‰
    import negmas.tournaments.tournaments as nt
    global _ORIGINAL_RUN_WORLDS
    _ORIGINAL_RUN_WORLDS = nt._run_worlds
    nt._run_worlds = traced_run_worlds
    # ç›‘æ§ futures çŠ¶æ€ï¼šmonkeypatch _submit_all ä»¥åœ¨æäº¤æ—¶æŒ‚å›è°ƒ
    _ORIGINAL_SUBMIT_ALL = nt._submit_all

    def traced_submit_all(
        executor,
        assigned,
        run_ids,
        world_generator,
        score_calculator,
        world_progress_callback,
        override_ran_worlds,
        attempts_path,
        verbose,
        max_attempts,
    ):
        # å…ˆæ„å»º run_id/name åˆ—è¡¨ï¼Œä¸ future åˆ—è¡¨é¡ºåºå¯¹åº”
        mapped_run_ids = []
        mapped_names = []
        for worlds_params in assigned:
            rid = nt._hash(worlds_params)
            if rid in run_ids:
                continue
            mapped_run_ids.append(rid)
            names = []
            try:
                for wp in worlds_params:
                    if isinstance(wp, dict):
                        info = wp.get("world_params") or {}
                        names.append(info.get("name") or info.get("config_id"))
            except Exception:
                pass
            mapped_names.append(names)

        future_results, timeout = _ORIGINAL_SUBMIT_ALL(
            executor,
            assigned,
            run_ids,
            world_generator,
            score_calculator,
            world_progress_callback,
            override_ran_worlds,
            attempts_path,
            verbose,
            max_attempts,
        )

        for idx, fut in enumerate(future_results):
            rid = mapped_run_ids[idx] if idx < len(mapped_run_ids) else None
            nm = mapped_names[idx] if idx < len(mapped_names) else None
            log_future("future_submitted", run_id=rid, names=nm)
            # ä¾¿äºç›‘æ§æ—¶å…³è”
            fut._run_id = rid
            fut._names = nm

            def _cb(f, rid=rid, nm=nm):
                info = {"run_id": rid, "names": nm}
                if f.cancelled():
                    info["state"] = "cancelled"
                else:
                    exc = f.exception()
                    if exc is None:
                        info["state"] = "done"
                    else:
                        info["state"] = "error"
                        info["error"] = repr(exc)
                log_future("future_done", **info)

            fut.add_done_callback(_cb)

        # è®°å½•æ‰€æœ‰ future å¼•ç”¨ï¼Œå¯åŠ¨ä¸€ä¸ªç›‘æ§çº¿ç¨‹ï¼ˆæ¯ä¸ª executor åªå¯åŠ¨ä¸€æ¬¡ï¼‰
        monitored = getattr(executor, "_scml_monitored_futures", None)
        if monitored is None:
            monitored = []
            executor._scml_monitored_futures = monitored
        monitored.extend(future_results)

        if not getattr(executor, "_scml_monitor_started", False):
            try:
                t = threading.Thread(
                    target=monitor_executor, args=(executor, monitored), daemon=True
                )
                t.start()
                executor._scml_monitor_started = True
                log_future("monitor_started", max_workers=getattr(executor, "_max_workers", None))
            except Exception as e:
                log_future("monitor_start_error", error=str(e))

        return future_results, timeout

    nt._submit_all = traced_submit_all

    # æ›¿æ¢ executorï¼šæä¾› loky åç«¯ï¼ˆparallelism='loky' æˆ– 'loky:<fraction>'ï¼‰
    import concurrent.futures as cf
    from joblib.externals.loky import ProcessPoolExecutor as LokyExecutor
    _ORIGINAL_GET_EXECUTOR = nt._get_executor

    def _parse_max_workers(parallelism):
        if not isinstance(parallelism, str):
            return None
        if ":" in parallelism:
            try:
                frac = float(parallelism.split(":")[1])
                if 0 < frac <= 1:
                    return max(1, int(os.cpu_count() * frac))
            except Exception:
                return None
        return None

    def traced_get_executor(parallelism, verbose, total_timeout=None, scheduler_ip=None, scheduler_port=None):
        effective = parallelism
        requested = _REQUESTED_PARALLELISM
        if isinstance(requested, str) and requested.startswith("loky"):
            effective = requested
        if isinstance(effective, str) and effective.startswith("loky"):
            max_workers = _parse_max_workers(parallelism)
            exec_kwargs = {}
            if max_workers:
                exec_kwargs["max_workers"] = max_workers
            executor = LokyExecutor(**exec_kwargs)
            return executor, cf.as_completed
        return _ORIGINAL_GET_EXECUTOR(parallelism, verbose, total_timeout, scheduler_ip, scheduler_port)

    nt._get_executor = traced_get_executor

    # ç›‘æ§çº¿ç¨‹ï¼šå®šæœŸæ£€æŸ¥è¿›ç¨‹å­˜æ´»ä¸ pending futures
    def monitor_executor(executor, futures, interval=10):
        while True:
            time.sleep(interval)
            try:
                procs = getattr(executor, "_processes", {}) or {}
                alive = [pid for pid, p in procs.items() if p.is_alive()]
                pending = [f for f in futures if not f.done()]
                log_future(
                    "executor_monitor",
                    n_processes=len(alive),
                    pids=alive,
                    pending=len(pending),
                )
                # å¦‚æœæ— æ´»è·ƒè¿›ç¨‹ä½†ä»æœ‰ pendingï¼Œè®°å½•è¯¦ç»† run_id/åç§°ï¼Œå¿…è¦æ—¶å¯å–æ¶ˆï¼ˆæš‚ä¸å–æ¶ˆï¼Œä»…æ—¥å¿—ï¼‰
                if len(alive) == 0 and pending:
                    pending_info = []
                    for f in pending:
                        rid = getattr(f, "_run_id", None)
                        nm = getattr(f, "_names", None)
                        pending_info.append({"run_id": rid, "names": nm})
                    log_future("executor_stall", pending=len(pending), info=pending_info)
            except Exception as e:
                log_future("monitor_error", error=str(e))
                break

    from scml.utils import anac2024_std
    from scml.std.agents import RandomStdAgent, GreedyStdAgent, SyncRandomStdAgent
    from litaagent_std.litaagent_y import LitaAgentY
    from litaagent_std.litaagent_yr import LitaAgentYR
    from litaagent_std.litaagent_cir import LitaAgentCIR
    from litaagent_std.litaagent_n import LitaAgentN
    from litaagent_std.litaagent_p import LitaAgentP
    
    try:
        from scml_agents import get_agents
        TOP_AGENTS = get_agents(2025, as_class=True, top_only=5, track='std')
        print(f"âœ“ åŠ è½½ Top Agents ({len(TOP_AGENTS)}): {[a.__name__ for a in TOP_AGENTS]}")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•åŠ è½½ Top Agents: {e}")
        TOP_AGENTS = []

    # ä¸ run_std_quick ç›¸åŒçš„ agents
    competitors = [
        LitaAgentY, LitaAgentYR, LitaAgentCIR, LitaAgentN, LitaAgentP,
    ] + list(TOP_AGENTS) + [
        RandomStdAgent, GreedyStdAgent, SyncRandomStdAgent
    ]
    
    print("=" * 70)
    print("ğŸ”¬ æ·±åº¦è¯Šæ–­ - ä¸ run_std_quick ç›¸åŒè§„æ¨¡")
    print("=" * 70)
    print(f"å‚èµ›è€…æ•°é‡: {len(competitors)}")
    print(f"å‚èµ›è€…: {[c.__name__ for c in competitors]}")
    global _REQUESTED_PARALLELISM
    parallelism = os.environ.get("SCML_PARALLELISM", "loky")
    _REQUESTED_PARALLELISM = parallelism
    negmas_parallelism = (
        "parallel" if isinstance(parallelism, str) and parallelism.startswith("loky") else parallelism
    )
    print(f"é…ç½®: n_configs=3, n_steps=50, max_worlds_per_config=None")
    print(f"å¹¶è¡Œæ¨¡å¼: {parallelism}ï¼ˆä¼ ç»™ negmas: {negmas_parallelism}ï¼‰")
    print(f"ä¸»è¿›ç¨‹ PID: {os.getpid()}")
    print(f"ç›‘æ§æ—¥å¿—: {MONITOR_LOG}")
    print(f"ä¸»æ—¥å¿—: {MAIN_LOG}")
    print(f"Negmas è¾“å‡ºç›®å½•: {TOURNAMENT_DIR}")
    print(f"Future è¿½è¸ª: {FUTURE_TRACE}")
    print()
    
    # è®°å½•åˆ°ä¸»æ—¥å¿—
    log_to_file(MAIN_LOG, "=" * 80)
    log_to_file(MAIN_LOG, "æ·±åº¦è¯Šæ–­å¯åŠ¨")
    log_to_file(MAIN_LOG, f"å‚èµ›è€…: {[c.__name__ for c in competitors]}")
    log_to_file(MAIN_LOG, f"PID: {os.getpid()}")
    log_to_file(MAIN_LOG, f"å¹¶è¡Œæ¨¡å¼: {parallelism}ï¼ˆnegmas: {negmas_parallelism}ï¼‰")
    log_to_file(MAIN_LOG, "=" * 80)
    
    # å¯åŠ¨ç›‘æ§
    monitor = ProcessMonitor(MONITOR_LOG, interval=5)
    monitor.start()
    
    # æ³¨å†Œé€€å‡ºå¤„ç†
    def cleanup():
        monitor.stop()
        log_to_file(MAIN_LOG, "ç¨‹åºé€€å‡º")
    atexit.register(cleanup)
    
    # ä¿¡å·å¤„ç†
    def signal_handler(sig, frame):
        log_to_file(MAIN_LOG, f"æ”¶åˆ°ä¿¡å·: {sig}")
        monitor.stop()
        sys.exit(1)
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    print("ğŸš€ å¼€å§‹æ¯”èµ› (æ— è¶…æ—¶é™åˆ¶)...")
    log_to_file(MAIN_LOG, "æ¯”èµ›å¼€å§‹")
    
    start_time = time.time()
    
    try:
        results = anac2024_std(
            competitors=competitors,
            n_configs=3,
            n_runs_per_world=1,
            n_steps=50,
            # ä¸è®¾ç½® max_worlds_per_configï¼Œç”Ÿæˆæ‰€æœ‰ç»„åˆ
            print_exceptions=True,
            verbose=False,
            parallelism=negmas_parallelism,
            tournament_path=TOURNAMENT_DIR,
            # ä¸è®¾ç½® total_timeout
        )
        
        elapsed = time.time() - start_time
        log_to_file(MAIN_LOG, f"æ¯”èµ›å®Œæˆ! è€—æ—¶: {elapsed:.1f}s")
        
        print("\n" + "=" * 70)
        print(f"âœ… æ¯”èµ›å®Œæˆ! è€—æ—¶: {elapsed:.1f}s")
        print("=" * 70)
        
        if hasattr(results, 'winners') and results.winners:
            winners = [w.split('.')[-1] for w in results.winners]
            print(f"ğŸ† å† å†›: {winners}")
            log_to_file(MAIN_LOG, f"å† å†›: {winners}")
        
        if (
            hasattr(results, 'total_scores')
            and results.total_scores is not None
            and not results.total_scores.empty
            and "score" in results.total_scores
        ):
            print("\nğŸ“Š æ’å:")
            sorted_scores = results.total_scores.sort_values("score", ascending=False)
            for rank, (idx, row) in enumerate(sorted_scores.iterrows(), 1):
                agent_name = row["agent_type"].split(".")[-1]
                score = row['score']
                print(f"  {rank}. {agent_name}: {score:.4f}")
                log_to_file(MAIN_LOG, f"æ’å {rank}: {agent_name} = {score:.4f}")
        else:
            print("\nğŸ“Š æ’åä¿¡æ¯ä¸å¯ç”¨ï¼ˆtotal_scores ä¸ºç©ºæˆ–ç¼ºå°‘ score åˆ—ï¼‰")
            log_to_file(MAIN_LOG, "total_scores ä¸ºç©ºæˆ–ç¼ºå°‘ score åˆ—ï¼Œè·³è¿‡æ’åè¾“å‡º")
                
    except KeyboardInterrupt:
        elapsed = time.time() - start_time
        log_to_file(MAIN_LOG, f"ç”¨æˆ·ä¸­æ–­! è¿è¡Œæ—¶é—´: {elapsed:.1f}s")
        print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­ (è¿è¡Œ {elapsed:.1f}s)")
    except Exception as e:
        elapsed = time.time() - start_time
        log_to_file(MAIN_LOG, f"é”™è¯¯: {e}")
        log_to_file(MAIN_LOG, f"è¿è¡Œæ—¶é—´: {elapsed:.1f}s")
        import traceback
        log_to_file(MAIN_LOG, traceback.format_exc())
        print(f"\nâŒ é”™è¯¯: {e}")
        traceback.print_exc()
    finally:
        monitor.stop()
        
    print(f"\nğŸ“ ç›‘æ§æ—¥å¿—å·²ä¿å­˜åˆ°: {MONITOR_LOG}")


if __name__ == "__main__":
    main()
